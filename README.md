# Polygraf Meeting Summarizer

> A scalable, asynchronous Python backend that turns long meeting recordings into accurate transcripts and concise, AI-generated summaries.

This system is built on a distributed, queue-based architecture using Redis and Docker. It can process large audio/video files in the background without blocking the user, providing a job ID to track progress and retrieve the final results.

[![FastAPI](https://img.shields.io/badge/FastAPI-0.111+-blue.svg)](https://fastapi.tiangolo.com/)
[![Redis](https://img.shields.io/badge/Redis-7+-D82C20.svg)](https://redis.io/)
[![Docker Compose](https://img.shields.io/badge/Docker%20Compose-supported-2496ED.svg)](https://docs.docker.com/compose/)
[![Whisper](https://img.shields.io/badge/OpenAI-Whisper-black.svg)](https://github.com/openai/whisper)
[![Google Gemini](https://img.shields.io/badge/Google-Gemini-4285F4.svg)](https://ai.google.dev/)

---

## What it does

- Accepts **mp4/wav** meeting recordings + a **speaker diarization JSON**
- Splits audio into chunks, **transcribes** with Whisper, and **summarizes** via Google Gemini
- Scales horizontally with **multiple workers** coordinated by **Redis queues**
- Provides **non-blocking** API: submit a job, **poll by `job_id`**, retrieve results when done

---

## Core Principle

- **The API does no heavy work** â€” it only accepts jobs and reports status.
- **Redis** is the central hub for queues, job state, and results.
- **Workers** do the compute (splitting â†’ transcription â†’ summarization) asynchronously.

---

## ğŸ—ï¸ System Architecture

![Polygraf Architecture](./architecture.png)

**Pipeline (3 Workers via Redis):**

1. **Worker A â€“ Splitter**
   - Extracts audio from video (if needed)
   - Reads diarization JSON and splits the audio into **N** chunks
   - Enqueues **N** transcription tasks

2. **Worker B â€“ Transcriber**
   - Processes each chunk from the transcription queue
   - Runs **Whisper** to produce text
   - Appends text fragments to Redis and increments `processed_chunks`
   - On last chunk, enqueues a final **summary** task

3. **Worker C â€“ Summarizer**
   - Fetches all transcript fragments
   - Formats prompt + calls **Google Gemini**
   - Stores the final JSON summary in Redis and marks the job **complete**

---

## ğŸ§° Tech Stack

- **API**: FastAPI (Uvicorn)
- **Queues & State**: Redis
- **Transcription**: OpenAI Whisper
- **Summarization**: Google Gemini
- **Media I/O**: pydub, MoviePy
- **Containerization**: Docker & Docker Compose

> Compose services: `redis`, `api`, `worker-splitter`, `worker-transcriber`, `worker-summarizer`.

---

## ğŸ“¦ Repository

- GitHub: <https://github.com/Manishrdy/polygraf_python_assessment>

---

## ğŸ“ Project Layout (high-level)
```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 # FastAPI app (routes: /jobs, /jobs/{job_id})
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ jobs.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ audio_extractor.py
â”‚   â”‚   â”œâ”€â”€ consumer.py
â”‚   â”‚   â”œâ”€â”€ redis_service.py
â”‚   â”‚   â”œâ”€â”€ transcriber.py
â”‚   â”œâ”€â”€ workers/
â”‚   â”‚   â”œâ”€â”€ splitter.py
â”‚   â”‚   â”œâ”€â”€ transcriber.py
â”‚   â”‚   â””â”€â”€ summarizer.py
â”œâ”€â”€ data/                       # Create this folder in root            
â”‚   â”œâ”€â”€ audio.wav               # Add your audio.wav 
â”‚   â”œâ”€â”€ diarization.json        # Add your diarization.json
â”œâ”€â”€ logs/
â”œâ”€â”€ architecture.png            # Architecture diagram (shown above)
â”œâ”€â”€ docker-compose.yaml         # Multi-service definition
â”œâ”€â”€ .env.example                # Example environment file (see below)
â””â”€â”€ README.md
```

---

## Requirements

- **Docker Desktop** (or Docker Engine + Compose)
- **API keys** for **Google Gemini**
- Sufficient CPU/GPU for Whisper (CPU works; GPU recommended for large files)

---

## Environment Setup

Create a `.env` file at the repo root:

```env
# -- App Config --
APP_ENV=development

# -- API Keys (Required) --
GEMINI_API_KEY=AIzaSy...                # Required
GENAI_MODEL=gemini-2.5-flash

LOG_LEVEL=INFO
API_PORT=8000
WHISPER_MODEL=base
```
---

## Docker
```
# Build images and start all services
docker compose up --build -d

# View logs
docker compose logs -f

# View all servicers
docker compose ps

# Stop and remove container
docker compose down

# Delete docker images
docker compose down --volumes --rmi all   

#Reclaim storage
docker system prune -a
```

## API Endpoints

- Colletion: <https://grey-moon-445797.postman.co/workspace/Manish~283d32b7-e13d-4cd5-a9d8-96c6fb685e4b/collection/17079845-59e50f92-a031-432a-9313-b023d340143a?action=share&creator=17079845>

## Final Output
```
{
  "job_id": "330b989e-1f0a-4f35-8199-1670c4a42bc6",
  "status": "complete",
  "summary": {
    "keypoints": ["..."],
    "decisions": ["..."],
    "action_items": ["..."]
  },
  "per_person": {
    "Interviewer": [
      "Hi, Manish. So welcome...",
      "How do you approach design?"
    ],
    "Manish Reddy": [
      "Thank you...",
      "What are your core goals..."
    ]
  },
  "speakers": [
    "Interviewer",
    "Manish Reddy"
  ],
  "counts": {
    "Interviewer": 28,
    "Manish Reddy": 37
  }
}
```
